Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]Downloading: 5.16kB [00:00, 3.02MB/s]                   
Downloading:   0%|          | 0.00/954 [00:00<?, ?B/s]Downloading: 1.91kB [00:00, 1.23MB/s]                 
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
Traceback (most recent call last):
  File "run_baseline.py", line 49, in <module>
    N_pos, N_neg = len([d for d in dataset["dataset"] if d["label"]==1]), len([d for d in dataset["dataset"] if d["label"]==0])
KeyError: 'dataset'
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0  xsumfaith  1250    127   1123    0.1016
loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
  2%|1         | 20/1250 [00:43<44:25,  2.17s/it]  3%|3         | 40/1250 [01:23<41:45,  2.07s/it]  5%|4         | 59/1250 [01:29<30:07,  1.52s/it]
Traceback (most recent call last):
  File "run_baseline.py", line 81, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 67, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 23, in score
    scores = self.scorer.compute_score(documents, generateds, aggregate=False)
  File "/home/phillab/feqa/feqa.py", line 175, in compute_score
    doc_ids, questions, gold_answers = self._generate_questions(summaries)
  File "/home/phillab/feqa/feqa.py", line 95, in _generate_questions
    hypotheses = self.qg_model.sample(batch, beam=self.beam_size, lenpen=1.0, max_len_b=self.max_length, min_len=1, no_repeat_ngram_size=3)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/models/bart/hub_interface.py", line 102, in sample
    hypos = self.generate(input, beam, verbose, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/models/bart/hub_interface.py", line 118, in generate
    prefix_tokens=sample['net_input']['src_tokens'].new_zeros((len(tokens), 1)).fill_(self.task.source_dictionary.bos()),
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/tasks/fairseq_task.py", line 265, in inference_step
    return generator.generate(models, sample, prefix_tokens=prefix_tokens)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/sequence_generator.py", line 113, in generate
    return self._generate(model, sample, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/sequence_generator.py", line 342, in _generate
    gen_tokens = tokens[bbsz_idx].tolist()
KeyboardInterrupt
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0  xsumfaith  1250    127   1123    0.1016
loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
  8%|8         | 100/1250 [03:01<34:43,  1.81s/it] 16%|#6        | 200/1250 [05:13<26:38,  1.52s/it] 24%|##4       | 300/1250 [07:32<23:08,  1.46s/it] 32%|###2      | 400/1250 [09:33<19:20,  1.37s/it] 40%|####      | 500/1250 [12:13<18:06,  1.45s/it] 48%|####8     | 600/1250 [15:58<18:37,  1.72s/it] 56%|#####6    | 700/1250 [18:53<15:51,  1.73s/it] 64%|######4   | 800/1250 [21:39<12:48,  1.71s/it] 72%|#######2  | 900/1250 [24:31<09:58,  1.71s/it] 80%|########  | 1000/1250 [27:00<06:51,  1.64s/it] 88%|########8 | 1100/1250 [30:58<04:40,  1.87s/it] 96%|#########6| 1200/1250 [35:08<01:43,  2.06s/it]100%|##########| 1250/1250 [35:08<00:00,  1.69s/it]
                  xsumfaith
model_name input           
FEQA       doc     0.534111
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
 11%|#         | 99/931 [00:40<05:43,  2.42it/s]
Traceback (most recent call last):
  File "run_baseline.py", line 84, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 70, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 60, in score
    new_scores = self.score_feqa([d[1] for d in new_samples], [d[2] for d in new_samples])
  File "/home/phillab/summac/model_baseline.py", line 44, in score_feqa
    scores = self.scorer.compute_score(documents, generateds, aggregate=False)
  File "/home/phillab/feqa/feqa.py", line 175, in compute_score
    doc_ids, questions, gold_answers = self._generate_questions(summaries)
  File "/home/phillab/feqa/feqa.py", line 95, in _generate_questions
    hypotheses = self.qg_model.sample(batch, beam=self.beam_size, lenpen=1.0, max_len_b=self.max_length, min_len=1, no_repeat_ngram_size=3)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/models/bart/hub_interface.py", line 102, in sample
    hypos = self.generate(input, beam, verbose, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/models/bart/hub_interface.py", line 118, in generate
    prefix_tokens=sample['net_input']['src_tokens'].new_zeros((len(tokens), 1)).fill_(self.task.source_dictionary.bos()),
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/tasks/fairseq_task.py", line 265, in inference_step
    return generator.generate(models, sample, prefix_tokens=prefix_tokens)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/sequence_generator.py", line 113, in generate
    return self._generate(model, sample, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/fairseq/sequence_generator.py", line 340, in _generate
    gen_ngrams = [{} for bbsz_idx in range(bsz * beam_size)]
KeyboardInterrupt
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
 11%|#         | 100/931 [02:43<22:35,  1.63s/it] 21%|##1       | 200/931 [05:13<18:57,  1.56s/it] 32%|###2      | 300/931 [07:45<16:12,  1.54s/it] 43%|####2     | 400/931 [10:18<13:35,  1.54s/it] 54%|#####3    | 500/931 [12:53<11:03,  1.54s/it] 64%|######4   | 600/931 [15:39<08:44,  1.58s/it] 75%|#######5  | 700/931 [18:08<05:58,  1.55s/it] 86%|########5 | 800/931 [20:41<03:22,  1.54s/it] 97%|#########6| 900/931 [23:30<00:49,  1.59s/it]100%|##########| 931/931 [23:30<00:00,  1.52s/it]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s] 15%|#4        | 100/671 [02:21<13:28,  1.42s/it] 30%|##9       | 200/671 [04:46<11:14,  1.43s/it] 45%|####4     | 300/671 [07:19<09:08,  1.48s/it] 59%|#####9    | 399/671 [11:45<08:00,  1.77s/it]
Traceback (most recent call last):
  File "run_baseline.py", line 84, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 70, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 60, in score
    new_scores = self.score_feqa([d[1] for d in new_samples], [d[2] for d in new_samples])
  File "/home/phillab/summac/model_baseline.py", line 44, in score_feqa
    scores = self.scorer.compute_score(documents, generateds, aggregate=False)
  File "/home/phillab/feqa/feqa.py", line 178, in compute_score
    predictions_dict = self._run_squad(squad_format)
  File "/home/phillab/feqa/feqa.py", line 146, in _run_squad
    ret = subprocess.check_output(cmd, shell=True)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 356, in check_output
    **kwargs).stdout
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 438, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command 'python /home/phillab/models/feqa/squad1.0/run_squad.py --model_type bert --model_name_or_path /home/phillab/models/feqa/squad1.0 --do_eval --overwrite_cache --do_lower_case --predict_file /tmp/tmp2fdy7my6/squad_input.json --per_gpu_train_batch_size 12 --max_seq_length 384 --doc_stride 128 --output_dir /tmp/tmp2fdy7my6' returned non-zero exit status 1.
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 157888.45it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
 15%|#4        | 100/671 [02:36<14:55,  1.57s/it] 30%|##9       | 200/671 [05:00<11:43,  1.49s/it] 45%|####4     | 300/671 [07:34<09:20,  1.51s/it] 60%|#####9    | 400/671 [18:03<15:21,  3.40s/it] 75%|#######4  | 500/671 [29:02<12:58,  4.55s/it] 89%|########9 | 600/671 [39:28<06:04,  5.13s/it]100%|##########| 671/671 [39:28<00:00,  3.53s/it]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s] 16%|#5        | 100/634 [06:50<36:32,  4.11s/it] 32%|###1      | 200/634 [20:24<46:50,  6.48s/it] 47%|####7     | 300/634 [31:47<36:57,  6.64s/it] 63%|######3   | 400/634 [41:34<24:42,  6.34s/it] 79%|#######8  | 500/634 [56:30<16:15,  7.28s/it] 95%|#########4| 600/634 [1:08:26<04:06,  7.24s/it]100%|##########| 634/634 [1:08:26<00:00,  6.48s/it]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]  8%|7         | 100/1281 [11:53<2:20:28,  7.14s/it] 16%|#5        | 200/1281 [22:53<2:02:52,  6.82s/it] 23%|##3       | 300/1281 [33:53<1:49:52,  6.72s/it] 31%|###1      | 400/1281 [46:20<1:43:00,  7.02s/it] 39%|###9      | 500/1281 [57:05<1:28:40,  6.81s/it] 47%|####6     | 600/1281 [1:02:57<1:04:35,  5.69s/it] 55%|#####4    | 700/1281 [1:05:01<41:02,  4.24s/it]   62%|######2   | 800/1281 [1:06:57<26:07,  3.26s/it] 70%|#######   | 900/1281 [1:08:52<16:29,  2.60s/it] 78%|#######8  | 1000/1281 [1:10:45<10:02,  2.15s/it] 86%|########5 | 1100/1281 [1:12:40<05:33,  1.84s/it] 94%|#########3| 1200/1281 [1:14:16<02:07,  1.57s/it]100%|##########| 1281/1281 [1:14:16<00:00,  3.48s/it]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s] 12%|#1        | 100/850 [08:54<1:06:46,  5.34s/it] 24%|##3       | 200/850 [17:21<56:08,  5.18s/it]   35%|###5      | 300/850 [25:53<47:15,  5.15s/it] 47%|####7     | 400/850 [34:11<38:09,  5.09s/it] 59%|#####8    | 500/850 [42:10<29:02,  4.98s/it] 71%|#######   | 600/850 [50:50<21:03,  5.05s/it] 82%|########2 | 700/850 [58:34<12:17,  4.92s/it] 94%|#########4| 800/850 [1:06:23<04:02,  4.85s/it]100%|##########| 850/850 [1:06:23<00:00,  4.69s/it]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]  8%|8         | 100/1250 [02:59<34:27,  1.80s/it] 16%|#6        | 200/1250 [05:12<26:36,  1.52s/it] 24%|##4       | 300/1250 [07:32<23:12,  1.47s/it] 32%|###2      | 400/1250 [09:33<19:21,  1.37s/it] 40%|####      | 500/1250 [12:14<18:09,  1.45s/it] 48%|####8     | 600/1250 [15:11<16:54,  1.56s/it] 56%|#####6    | 700/1250 [18:05<14:50,  1.62s/it] 64%|######4   | 800/1250 [20:51<12:15,  1.63s/it] 72%|#######2  | 900/1250 [23:44<09:41,  1.66s/it] 80%|########  | 1000/1250 [26:08<06:38,  1.59s/it] 88%|########8 | 1100/1250 [28:19<03:46,  1.51s/it] 96%|#########6| 1200/1250 [30:38<01:13,  1.47s/it]100%|##########| 1250/1250 [30:38<00:00,  1.47s/it]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 183233.87it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]100%|##########| 671/671 [00:00<00:00, 106953.64it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]100%|##########| 634/634 [00:00<00:00, 92080.36it/s]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]100%|##########| 1281/1281 [00:00<00:00, 132161.74it/s]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 189908.83it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]100%|##########| 1250/1250 [00:00<00:00, 144058.91it/s]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 79032.10it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]100%|##########| 671/671 [00:00<00:00, 146254.64it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]100%|##########| 634/634 [00:00<00:00, 89043.29it/s]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]100%|##########| 1281/1281 [00:00<00:00, 104005.10it/s]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 221824.19it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]100%|##########| 1250/1250 [00:00<00:00, 146641.68it/s]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 174123.65it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]100%|##########| 671/671 [00:00<00:00, 97004.03it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]100%|##########| 634/634 [00:00<00:00, 95379.80it/s]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]100%|##########| 1281/1281 [00:00<00:00, 135696.51it/s]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 209900.41it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]100%|##########| 1250/1250 [00:00<00:00, 136732.74it/s]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 172067.38it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]100%|##########| 671/671 [00:00<00:00, 105108.23it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]100%|##########| 634/634 [00:00<00:00, 95695.58it/s]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]100%|##########| 1281/1281 [00:00<00:00, 103335.00it/s]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 147393.68it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]100%|##########| 1250/1250 [00:00<00:00, 140835.42it/s]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   931    799    132  0.858217
1      frank   671    223    448  0.332340
2     pt_any   634     42    592  0.066246
3  summ_corr  1281    637    644  0.497268
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    127   1123  0.101600
======= factcc ========
  0%|          | 0/931 [00:00<?, ?it/s]100%|##########| 931/931 [00:00<00:00, 173922.01it/s]
======= frank ========
  0%|          | 0/671 [00:00<?, ?it/s]100%|##########| 671/671 [00:00<00:00, 105529.94it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]100%|##########| 634/634 [00:00<00:00, 107576.71it/s]
======= summ_corr ========
  0%|          | 0/1281 [00:00<?, ?it/s]100%|##########| 1281/1281 [00:00<00:00, 104079.64it/s]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 152984.83it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]100%|##########| 1250/1250 [00:00<00:00, 140907.33it/s]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.51646  0.667996  0.601552   0.520468  0.534497   0.525792
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   503    441     62  0.876740
1      frank  1575    529   1046  0.335873
2     pt_any   634     41    593  0.064669
3  summ_corr   400    312     88  0.780000
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    130   1120  0.104000
======= factcc ========
  0%|          | 0/503 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
 20%|#9        | 100/503 [03:26<13:50,  2.06s/it] 40%|###9      | 200/503 [06:12<09:14,  1.83s/it] 60%|#####9    | 300/503 [09:07<06:03,  1.79s/it] 80%|#######9  | 400/503 [11:47<02:56,  1.72s/it] 99%|#########9| 500/503 [14:51<00:05,  1.76s/it]100%|##########| 503/503 [14:51<00:00,  1.77s/it]
======= frank ========
  0%|          | 0/1575 [00:00<?, ?it/s]  6%|6         | 100/1575 [01:54<28:05,  1.14s/it] 13%|#2        | 200/1575 [04:28<31:31,  1.38s/it] 19%|#9        | 300/1575 [06:30<27:46,  1.31s/it] 25%|##5       | 400/1575 [09:02<27:14,  1.39s/it] 32%|###1      | 500/1575 [11:47<26:35,  1.48s/it] 38%|###8      | 600/1575 [14:16<24:07,  1.49s/it] 44%|####4     | 700/1575 [16:33<21:06,  1.45s/it] 51%|#####     | 800/1575 [25:15<34:12,  2.65s/it] 57%|#####7    | 900/1575 [33:13<37:17,  3.32s/it] 63%|######3   | 999/1575 [37:19<21:30,  2.24s/it]
Traceback (most recent call last):
  File "run_baseline.py", line 85, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 71, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 63, in score
    new_scores = self.score_feqa([d[1] for d in new_samples], [d[2] for d in new_samples])
  File "/home/phillab/summac/model_baseline.py", line 47, in score_feqa
    scores = self.scorer.compute_score(documents, generateds, aggregate=False)
  File "/home/phillab/feqa/feqa.py", line 178, in compute_score
    predictions_dict = self._run_squad(squad_format)
  File "/home/phillab/feqa/feqa.py", line 146, in _run_squad
    ret = subprocess.check_output(cmd, shell=True)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 356, in check_output
    **kwargs).stdout
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 438, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command 'python /home/phillab/models/feqa/squad1.0/run_squad.py --model_type bert --model_name_or_path /home/phillab/models/feqa/squad1.0 --do_eval --overwrite_cache --do_lower_case --predict_file /tmp/tmpjpylenvq/squad_input.json --per_gpu_train_batch_size 12 --max_seq_length 384 --doc_stride 128 --output_dir /tmp/tmpjpylenvq' returned non-zero exit status 1.
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   503    441     62  0.876740
1      frank  1575    529   1046  0.335873
2     pt_any   634     41    593  0.064669
3  summ_corr   400    312     88  0.780000
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    130   1120  0.104000
======= factcc ========
  0%|          | 0/503 [00:00<?, ?it/s]100%|##########| 503/503 [00:00<00:00, 142280.48it/s]
======= frank ========
  0%|          | 0/1575 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
  6%|6         | 100/1575 [02:10<32:05,  1.31s/it] 13%|#2        | 200/1575 [04:43<32:57,  1.44s/it] 19%|#9        | 300/1575 [06:46<28:28,  1.34s/it] 25%|##5       | 400/1575 [09:17<27:33,  1.41s/it] 32%|###1      | 500/1575 [12:01<26:45,  1.49s/it] 38%|###8      | 600/1575 [14:30<24:13,  1.49s/it] 44%|####4     | 700/1575 [16:47<21:09,  1.45s/it] 51%|#####     | 800/1575 [25:25<34:04,  2.64s/it] 57%|#####7    | 900/1575 [33:21<37:08,  3.30s/it] 63%|######3   | 1000/1575 [42:02<37:17,  3.89s/it] 70%|######9   | 1100/1575 [52:21<36:23,  4.60s/it] 76%|#######6  | 1200/1575 [1:01:55<30:53,  4.94s/it] 83%|########2 | 1300/1575 [1:12:31<24:37,  5.37s/it] 89%|########8 | 1399/1575 [1:16:53<09:40,  3.30s/it]
Traceback (most recent call last):
  File "run_baseline.py", line 85, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 71, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 63, in score
    new_scores = self.score_feqa([d[1] for d in new_samples], [d[2] for d in new_samples])
  File "/home/phillab/summac/model_baseline.py", line 47, in score_feqa
    scores = self.scorer.compute_score(documents, generateds, aggregate=False)
  File "/home/phillab/feqa/feqa.py", line 178, in compute_score
    predictions_dict = self._run_squad(squad_format)
  File "/home/phillab/feqa/feqa.py", line 146, in _run_squad
    ret = subprocess.check_output(cmd, shell=True)
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 356, in check_output
    **kwargs).stdout
  File "/home/phillab/anaconda3/envs/feqa/lib/python3.6/subprocess.py", line 438, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command 'python /home/phillab/models/feqa/squad1.0/run_squad.py --model_type bert --model_name_or_path /home/phillab/models/feqa/squad1.0 --do_eval --overwrite_cache --do_lower_case --predict_file /tmp/tmphfnzbq2e/squad_input.json --per_gpu_train_batch_size 12 --max_seq_length 384 --doc_stride 128 --output_dir /tmp/tmphfnzbq2e' returned non-zero exit status 1.
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   503    441     62  0.876740
1      frank  1575    529   1046  0.335873
2     pt_any   634     41    593  0.064669
3  summ_corr   400    312     88  0.780000
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    130   1120  0.104000
======= factcc ========
  0%|          | 0/503 [00:00<?, ?it/s]100%|##########| 503/503 [00:00<00:00, 140330.91it/s]
======= frank ========
  0%|          | 0/1575 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
  6%|6         | 100/1575 [02:08<31:42,  1.29s/it] 13%|#2        | 200/1575 [04:42<32:47,  1.43s/it] 19%|#9        | 300/1575 [06:44<28:24,  1.34s/it] 25%|##5       | 400/1575 [09:15<27:33,  1.41s/it] 32%|###1      | 500/1575 [12:00<26:44,  1.49s/it] 38%|###8      | 600/1575 [14:28<24:11,  1.49s/it] 44%|####4     | 700/1575 [16:45<21:08,  1.45s/it] 51%|#####     | 800/1575 [25:25<34:08,  2.64s/it] 57%|#####7    | 900/1575 [33:22<37:13,  3.31s/it] 63%|######3   | 1000/1575 [42:03<37:20,  3.90s/it] 70%|######9   | 1100/1575 [52:24<36:26,  4.60s/it] 76%|#######6  | 1200/1575 [1:01:58<30:56,  4.95s/it] 83%|########2 | 1300/1575 [1:12:34<24:38,  5.38s/it] 89%|########8 | 1400/1575 [2:00:37<36:20, 12.46s/it] 95%|#########5| 1500/1575 [2:09:35<12:54, 10.33s/it]100%|##########| 1575/1575 [2:09:35<00:00,  4.94s/it]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   503    441     62  0.876740
1      frank  1575    529   1046  0.335873
2     pt_any   634     41    593  0.064669
3  summ_corr   400    312     88  0.780000
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    130   1120  0.104000
======= factcc ========
  0%|          | 0/503 [00:00<?, ?it/s]100%|##########| 503/503 [00:00<00:00, 135630.66it/s]
======= frank ========
  0%|          | 0/1575 [00:00<?, ?it/s]100%|##########| 1575/1575 [00:00<00:00, 132102.08it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s] 16%|#5        | 99/634 [00:00<00:00, 7031.58it/s]
Traceback (most recent call last):
  File "run_baseline.py", line 85, in <module>
    compute_doc_level(datas)
  File "run_baseline.py", line 71, in compute_doc_level
    doc_scores = scorer_doc(documents, summaries, progress=True)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 75, in __call__
    return self.score(inputs, generateds, **kwargs)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 54, in score
    batch_scores, timings_out = self.score_func(self.scorers, batch_inputs, batch_gens, partial=partial, printing=printing, extras=extras)
  File "/home/phillab/neural_textgen/utils_scoring.py", line 83, in sum_score
    scores = scorer['model'].score(paragraphs, generateds, partial=partial, printing=printing, **extras)
  File "/home/phillab/summac/model_baseline.py", line 60, in score
    self.load_model()
  File "/home/phillab/summac/model_baseline.py", line 23, in load_model
    from feqa import FEQA
  File "/home/phillab/feqa/feqa.py", line 4, in <module>
    import benepar
ModuleNotFoundError: No module named 'benepar'
Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)
Using custom data configuration default
Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)
        name     N  N_pos  N_neg  frac_pos
0     factcc   503    441     62  0.876740
1      frank  1575    529   1046  0.335873
2     pt_any   634     41    593  0.064669
3  summ_corr   400    312     88  0.780000
4   summeval   850    770     80  0.905882
5  xsumfaith  1250    130   1120  0.104000
======= factcc ========
  0%|          | 0/503 [00:00<?, ?it/s]100%|##########| 503/503 [00:00<00:00, 139995.68it/s]
======= frank ========
  0%|          | 0/1575 [00:00<?, ?it/s]100%|##########| 1575/1575 [00:00<00:00, 125116.55it/s]
======= pt_any ========
  0%|          | 0/634 [00:00<?, ?it/s]loading archive file /home/phillab/models/feqa/
| [src] dictionary: 50264 types
| [tgt] dictionary: 50264 types
WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

WARNING:tensorflow:From /home/phillab/anaconda3/envs/feqa/lib/python3.6/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
 16%|#5        | 100/634 [07:02<37:37,  4.23s/it] 32%|###1      | 200/634 [19:19<43:57,  6.08s/it] 47%|####7     | 300/634 [29:30<33:54,  6.09s/it] 63%|######3   | 400/634 [39:33<23:39,  6.07s/it] 79%|#######8  | 500/634 [54:21<15:48,  7.08s/it] 95%|#########4| 600/634 [1:07:15<04:08,  7.31s/it]100%|##########| 634/634 [1:07:15<00:00,  6.37s/it]
======= summ_corr ========
  0%|          | 0/400 [00:00<?, ?it/s] 25%|##5       | 100/400 [51:59<2:35:57, 31.19s/it] 50%|#####     | 200/400 [1:06:48<1:00:15, 18.08s/it] 75%|#######5  | 300/400 [1:21:26<23:03, 13.83s/it]  100%|##########| 400/400 [1:33:31<00:00, 11.23s/it]100%|##########| 400/400 [1:33:31<00:00, 14.03s/it]
======= summeval ========
  0%|          | 0/850 [00:00<?, ?it/s]100%|##########| 850/850 [00:00<00:00, 115989.15it/s]
======= xsumfaith ========
  0%|          | 0/1250 [00:00<?, ?it/s]  8%|8         | 100/1250 [1:30:02<17:15:23, 54.02s/it] 16%|#6        | 200/1250 [1:32:12<6:42:42, 23.01s/it]  24%|##4       | 300/1250 [1:35:07<3:30:36, 13.30s/it] 32%|###2      | 400/1250 [1:37:25<2:01:45,  8.59s/it] 40%|####      | 500/1250 [1:39:33<1:14:27,  5.96s/it] 48%|####8     | 600/1250 [1:42:19<48:42,  4.50s/it]   56%|#####6    | 700/1250 [1:45:09<32:50,  3.58s/it] 64%|######4   | 800/1250 [2:24:38<1:14:53,  9.99s/it] 72%|#######2  | 900/1250 [2:27:25<43:04,  7.38s/it]   80%|########  | 1000/1250 [2:30:33<23:41,  5.69s/it] 88%|########8 | 1100/1250 [2:32:42<10:51,  4.34s/it] 96%|#########6| 1200/1250 [2:34:59<02:51,  3.44s/it]100%|##########| 1250/1250 [2:34:59<00:00,  7.44s/it]
                   factcc     frank    pt_any  summ_corr  summeval  xsumfaith
model_name input                                                             
FEQA       doc    0.53458  0.699133  0.574549    0.61014  0.534497   0.558688
