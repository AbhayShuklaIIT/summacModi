{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import sklearn, torch, numpy as np, json, os, tqdm, pandas as pd, nltk, utils_misc, seaborn as sns, sys, glob\n",
    "sys.path.insert(0, \"/home/phillab/summac/\")\n",
    "from model_summac import SummaCHisto, SummaCZS, model_map\n",
    "from utils_summac_benchmark import SummaCBenchmark\n",
    "from utils_scoring import ScorerWrapper\n",
    "import utils_summac_benchmark\n",
    "\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "benchmark = SummaCBenchmark(cut=\"test\")\n",
    "benchmark.print_stats()\n",
    "\n",
    "def path_to_model_info(file_path):\n",
    "    toks = file_path.split(\"/\")\n",
    "    file_name = toks[-1].replace(\".bin\", \"\")\n",
    "    # vitc_sentence_percentile_ecn_f10.738.bin\n",
    "    model_type = \"histo\"\n",
    "    model_card, granularity, bins, nli_labels, acc = file_name.split(\"_\")\n",
    "    acc = float(acc.replace(\"bacc\", \"\").replace(\"f1\", \"\"))\n",
    "    return {\"model_type\": model_type, \"model_card\": model_card, \"granularity\": granularity, \"bins\": bins, \"acc\": acc, \"model_path\": file_path, \"nli_labels\": nli_labels}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-29 17:39:45,740 [6185] WARNING  datasets.builder:355: [JupyterRequire] Using custom data configuration default\n",
      "2021-07-29 17:39:45,744 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "2021-07-29 17:39:49,962 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        name     N  N_pos  N_neg  frac_pos\n",
      "0  cogensumm   400    312     88  0.780000\n",
      "1  xsumfaith  1250    130   1120  0.104000\n",
      "2   polytope   634     41    593  0.064669\n",
      "3     factcc   503    441     62  0.876740\n",
      "4   summeval   850    770     80  0.905882\n",
      "5      frank  1575    529   1046  0.335873\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 3: NLI Model Selection\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "scorers = []\n",
    "model_keys = list(model_map.keys())#+ [\"decomp\"]\n",
    "# model_keys = [\"decomp\"]\n",
    "\n",
    "for model_key in model_keys:\n",
    "    scorers.append({\"name\": \"ZS-%s\" % (model_key.upper().replace(\"-\", \"_\")), \"model\": SummaCZS(granularity=\"sentence\", model_name=model_key), \"sign\": 1, \"only_doc\": True})\n",
    "    \n",
    "    # Add a histogram based-model\n",
    "    model_files = glob.glob(\"/home/phillab/models/summac/%s_sentence*\" % (model_key))\n",
    "    if len(model_files) == 0:\n",
    "        print(\"No model for [%s] was found\" % (model_key))\n",
    "        continue\n",
    "    best = sorted([path_to_model_info(mf) for mf in model_files], key=lambda m: m[\"acc\"])[-1]\n",
    "    scorers.append({\"name\": \"Histo-%s\" % (model_key.upper().replace(\"-\", \"_\")), \"model\": SummaCHisto(bins=best[\"bins\"], nli_labels=best[\"nli_labels\"], models=[model_key], granularity=\"sentence\", start_file=best[\"model_path\"]), \"sign\": 1})\n",
    "\n",
    "scorer_doc = ScorerWrapper(scorers, scoring_method=\"sum\", max_batch_size=20, use_caching=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "benchmark = SummaCBenchmark(cut=\"test\")\n",
    "\n",
    "results = {}\n",
    "for dataset in benchmark.tasks:\n",
    "    print(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "    datas = dataset[\"task\"]\n",
    "    labels = [d[\"label\"] for d in datas]\n",
    "    utils_summac_benchmark.compute_doc_level(scorer_doc, datas)\n",
    "    \n",
    "    for pred_label in datas[0].keys():\n",
    "        if \"pred_\" not in pred_label or \"total\" in pred_label: continue\n",
    "        balanced_acc = sklearn.metrics.balanced_accuracy_score(labels, [d[pred_label] for d in datas])\n",
    "        model_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "        model_type, nli_name = model_name.split(\"-\")\n",
    "        k = (model_type, nli_name)\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(balanced_acc)\n",
    "\n",
    "cleaned_results = []\n",
    "for (model_type, nli), vs in results.items():\n",
    "    cleaned_results.append({\"nli_name\": nli, \"model_type\": model_type, \"score\": np.mean(vs)})\n",
    "    \n",
    "pd.DataFrame(cleaned_results).groupby([\"nli_name\", \"model_type\"]).agg({\"score\": \"sum\"}).style.set_precision(3).set_caption(\"Balanced Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= cogensumm ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-base-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 400/400 [23:02<00:00,  3.46s/it]\n",
      "  0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= xsumfaith ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1250/1250 [13:06<00:00,  1.59it/s]\n",
      "  0%|          | 0/634 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= polytope ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 634/634 [19:13<00:00,  1.82s/it]\n",
      "  0%|          | 0/503 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= factcc ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 503/503 [08:13<00:00,  1.02it/s]\n",
      "  5%|▍         | 40/850 [00:00<00:02, 325.65it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= summeval ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 850/850 [00:02<00:00, 383.71it/s]\n",
      "  0%|          | 0/1575 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= frank ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1575/1575 [39:21<00:00,  1.50s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9b\" ><caption>Balanced Accuracy</caption><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >score</th>    </tr>    <tr>        <th class=\"index_name level0\" >nli_name</th>        <th class=\"index_name level1\" >model_type</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row0\" class=\"row_heading level0 row0\" rowspan=2>ANLI</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row0\" class=\"row_heading level1 row0\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow0_col0\" class=\"data row0 col0\" >0.699</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row1\" class=\"row_heading level1 row1\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow1_col0\" class=\"data row1 col0\" >0.717</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row2\" class=\"row_heading level0 row2\" rowspan=2>MNLI</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row2\" class=\"row_heading level1 row2\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow2_col0\" class=\"data row2 col0\" >0.73</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row3\" class=\"row_heading level1 row3\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow3_col0\" class=\"data row3 col0\" >0.709</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row4\" class=\"row_heading level0 row4\" rowspan=2>MNLI_BASE</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row4\" class=\"row_heading level1 row4\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow4_col0\" class=\"data row4 col0\" >0.698</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row5\" class=\"row_heading level1 row5\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow5_col0\" class=\"data row5 col0\" >0.695</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row6\" class=\"row_heading level0 row6\" rowspan=2>SNLI_BASE</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row6\" class=\"row_heading level1 row6\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow6_col0\" class=\"data row6 col0\" >0.64</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row7\" class=\"row_heading level1 row7\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow7_col0\" class=\"data row7 col0\" >0.666</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row8\" class=\"row_heading level0 row8\" rowspan=2>SNLI_LARGE</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row8\" class=\"row_heading level1 row8\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow8_col0\" class=\"data row8 col0\" >0.624</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row9\" class=\"row_heading level1 row9\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow9_col0\" class=\"data row9 col0\" >0.666</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row10\" class=\"row_heading level0 row10\" rowspan=2>VITC</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row10\" class=\"row_heading level1 row10\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow10_col0\" class=\"data row10 col0\" >0.74</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row11\" class=\"row_heading level1 row11\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow11_col0\" class=\"data row11 col0\" >0.721</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row12\" class=\"row_heading level0 row12\" rowspan=2>VITC_BASE</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row12\" class=\"row_heading level1 row12\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow12_col0\" class=\"data row12 col0\" >0.712</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row13\" class=\"row_heading level1 row13\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow13_col0\" class=\"data row13 col0\" >0.679</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel0_row14\" class=\"row_heading level0 row14\" rowspan=2>VITC_ONLY</th>\n",
       "                        <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row14\" class=\"row_heading level1 row14\" >Histo</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow14_col0\" class=\"data row14 col0\" >0.728</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9blevel1_row15\" class=\"row_heading level1 row15\" >ZS</th>\n",
       "                        <td id=\"T_2c022b3a_efd5_11eb_ac7d_47dbd7e43e9brow15_col0\" class=\"data row15 col0\" >0.711</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f71c7b8b910>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "for scorer in scorers:\n",
    "        scorer[\"model\"].save_imager_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 4: Choice of NLI Category"
   ],
   "metadata": {
    "heading_collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scorers = []\n",
    "for model_key in [\"vitc\", \"mnli\", \"anli\"]:\n",
    "    for nli_labels in [\"e\", \"c\", \"n\", \"ec\", \"en\", \"cn\", \"ecn\"]:\n",
    "    \n",
    "        model_files = glob.glob(\"/home/phillab/models/summac/%s_sentence_percentile_%s*\" % (model_key, nli_labels))\n",
    "        if len(model_files) == 0:\n",
    "            print(\"No model for [%s, %s] was found\" % (model_key, nli_labels))\n",
    "            continue\n",
    "        best = sorted([path_to_model_info(mf) for mf in model_files], key=lambda m: m[\"acc\"])[-1]\n",
    "        scorers.append({\"name\": \"Histo-%s-%s\" % (model_key.upper().replace(\"-\", \"_\"), nli_labels), \"model\": SummaCHisto(bins=best[\"bins\"], nli_labels=best[\"nli_labels\"], models=[model_key], granularity=\"sentence\", start_file=best[\"model_path\"]), \"sign\": 1})\n",
    "\n",
    "scorer_doc = ScorerWrapper(scorers, max_batch_size=20, use_caching=True)\n",
    "print(\"%d scorers loaded\" % (len(scorers)))\n",
    "\n",
    "benchmark = SummaCBenchmark(cut=\"test\")\n",
    "\n",
    "results = {}\n",
    "for dataset in benchmark.tasks:\n",
    "    print(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "    datas = dataset[\"task\"]\n",
    "    labels = [d[\"label\"] for d in datas]\n",
    "    utils_summac_benchmark.compute_doc_level(scorer_doc, datas)\n",
    "    \n",
    "    for pred_label in datas[0].keys():\n",
    "        if \"pred_\" not in pred_label or \"total\" in pred_label: continue\n",
    "        balanced_acc = sklearn.metrics.balanced_accuracy_score(labels, [d[pred_label] for d in datas])\n",
    "        model_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "        model_type, nli_name, nli_labels = model_name.split(\"-\")\n",
    "        k = (nli_name, nli_labels)\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(balanced_acc)\n",
    "\n",
    "cleaned_results = []\n",
    "for (nli, nli_labels), vs in results.items():\n",
    "    cleaned_results.append({\"nli_name\": nli, \"nli_labels\": nli_labels, \"model_type\": model_type, \"score\": np.mean(vs)})\n",
    "    \n",
    "pd.DataFrame(cleaned_results).groupby([\"nli_name\", \"nli_labels\"]).agg({\"score\": \"sum\"}).style.set_precision(3).set_caption(\"Balanced Accuracy\")"
   ],
   "outputs": [],
   "metadata": {
    "hidden": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 5: Granularity Selection\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "scorers = []\n",
    "for model_key in [\"mnli\", \"vitc\"]:\n",
    "    for granularity in [\"sentence\", \"2sents\", \"paragraph\"]: # [\"sentence\", \"paragraph\"]\n",
    "        scorers.append({\"name\": \"ZS-%s-%s\" % (model_key.upper(), granularity), \"model\": SummaCZS(granularity=granularity, model_name=model_key), \"sign\": 1})\n",
    "    \n",
    "        model_files = glob.glob(\"/home/phillab/models/summac/%s_%s*\" % (model_key, granularity))\n",
    "        if len(model_files) == 0:\n",
    "            print(\"No model for [%s, %s] was found\" % (model_key, granularity))\n",
    "            continue\n",
    "        best = sorted([path_to_model_info(mf) for mf in model_files], key=lambda m: m[\"acc\"])[-1]\n",
    "        scorers.append({\"name\": \"Histo-%s-%s\" % (model_key.upper().replace(\"-\", \"_\"), granularity), \"model\": SummaCHisto(bins=best[\"bins\"], nli_labels=best[\"nli_labels\"], models=[model_key], granularity=granularity, start_file=best[\"model_path\"]), \"sign\": 1})\n",
    "\n",
    "scorer_doc = ScorerWrapper(scorers, max_batch_size=20, use_caching=True)\n",
    "print(\"%d scorers loaded\" % (len(scorers)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "12 scorers loaded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "benchmark = SummaCBenchmark(cut=\"test\")\n",
    "\n",
    "results = {}\n",
    "for dataset in benchmark.tasks:\n",
    "    print(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "    datas = dataset[\"task\"]\n",
    "    labels = [d[\"label\"] for d in datas]\n",
    "    utils_summac_benchmark.compute_doc_level(scorer_doc, datas)\n",
    "    \n",
    "    for pred_label in datas[0].keys():\n",
    "        if \"pred_\" not in pred_label or \"total\" in pred_label: continue\n",
    "        balanced_acc = sklearn.metrics.balanced_accuracy_score(labels, [d[pred_label] for d in datas])\n",
    "        model_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "        model_type, nli_name, gran = model_name.split(\"-\")\n",
    "        k = (model_type, nli_name, gran)\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(balanced_acc)\n",
    "\n",
    "cleaned_results = []\n",
    "for (model_type, nli, gran), vs in results.items():\n",
    "    cleaned_results.append({\"nli_name\": nli, \"granularity\": gran, \"model_type\": model_type, \"score\": np.mean(vs)})\n",
    "    \n",
    "pd.DataFrame(cleaned_results).groupby([\"nli_name\", \"granularity\", \"model_type\"]).agg({\"score\": \"sum\"}).style.set_precision(3).set_caption(\"Balanced Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-29 17:41:28,463 [6185] WARNING  datasets.builder:355: [JupyterRequire] Using custom data configuration default\n",
      "2021-07-29 17:41:28,465 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "2021-07-29 17:41:32,426 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= cogensumm ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 400/400 [22:57<00:00,  3.44s/it]\n",
      "  0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= xsumfaith ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1250/1250 [14:22<00:00,  1.45it/s]\n",
      "  0%|          | 0/634 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= polytope ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 634/634 [23:39<00:00,  2.24s/it]\n",
      "  0%|          | 0/503 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= factcc ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 503/503 [07:58<00:00,  1.05it/s]\n",
      "  9%|▉         | 80/850 [00:00<00:01, 700.97it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= summeval ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 850/850 [00:01<00:00, 705.64it/s]\n",
      "  0%|          | 0/1575 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= frank ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1575/1575 [30:29<00:00,  1.16s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2\" ><caption>Balanced Accuracy</caption><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >score</th>    </tr>    <tr>        <th class=\"index_name level0\" >nli_name</th>        <th class=\"index_name level1\" >granularity</th>        <th class=\"index_name level2\" >model_type</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level0_row0\" class=\"row_heading level0 row0\" rowspan=6>MNLI</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row0\" class=\"row_heading level1 row0\" rowspan=2>2sents</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row0\" class=\"row_heading level2 row0\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row0_col0\" class=\"data row0 col0\" >0.729</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row1\" class=\"row_heading level2 row1\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row1_col0\" class=\"data row1 col0\" >0.697</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row2\" class=\"row_heading level1 row2\" rowspan=2>paragraph</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row2\" class=\"row_heading level2 row2\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row2_col0\" class=\"data row2 col0\" >0.623</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row3\" class=\"row_heading level2 row3\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row3_col0\" class=\"data row3 col0\" >0.621</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row4\" class=\"row_heading level1 row4\" rowspan=2>sentence</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row4\" class=\"row_heading level2 row4\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row4_col0\" class=\"data row4 col0\" >0.73</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row5\" class=\"row_heading level2 row5\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row5_col0\" class=\"data row5 col0\" >0.703</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level0_row6\" class=\"row_heading level0 row6\" rowspan=6>VITC</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row6\" class=\"row_heading level1 row6\" rowspan=2>2sents</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row6\" class=\"row_heading level2 row6\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row6_col0\" class=\"data row6 col0\" >0.732</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row7\" class=\"row_heading level2 row7\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row7_col0\" class=\"data row7 col0\" >0.714</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row8\" class=\"row_heading level1 row8\" rowspan=2>paragraph</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row8\" class=\"row_heading level2 row8\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row8_col0\" class=\"data row8 col0\" >0.725</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row9\" class=\"row_heading level2 row9\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row9_col0\" class=\"data row9 col0\" >0.706</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level1_row10\" class=\"row_heading level1 row10\" rowspan=2>sentence</th>\n",
       "                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row10\" class=\"row_heading level2 row10\" >Histo</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row10_col0\" class=\"data row10 col0\" >0.74</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                        <th id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2level2_row11\" class=\"row_heading level2 row11\" >ZS</th>\n",
       "                        <td id=\"T_db6e65f4_f0c3_11eb_a7ae_f3abb70468b2row11_col0\" class=\"data row11 col0\" >0.718</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7faab46c7f50>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for scorer in scorers:\n",
    "        scorer[\"model\"].save_imager_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 6: SummaCZS Operator Choice"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "scorers = []\n",
    "for op1 in [\"min\", \"mean\", \"max\"]:\n",
    "    for op2 in [\"min\", \"mean\", \"max\"]:\n",
    "        scorers.append({\"name\": \"ZS-%s-%s\" % (op1, op2), \"model\": SummaCZS(granularity=\"sentence\", model_name=\"vitc\", op1=op1, op2=op2), \"sign\": 1})\n",
    "        \n",
    "scorer_doc = ScorerWrapper(scorers, max_batch_size=20, use_caching=True)\n",
    "print(\"%d scorers loaded\" % (len(scorers)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 scorers loaded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "benchmark = SummaCBenchmark(cut=\"test\")\n",
    "\n",
    "results = {}\n",
    "for dataset in benchmark.tasks:\n",
    "    print(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "    datas = dataset[\"task\"]\n",
    "    labels = [d[\"label\"] for d in datas]\n",
    "    utils_summac_benchmark.compute_doc_level(scorer_doc, datas)\n",
    "    \n",
    "    for pred_label in datas[0].keys():\n",
    "        if \"pred_\" not in pred_label or \"total\" in pred_label: continue\n",
    "        balanced_acc = sklearn.metrics.balanced_accuracy_score(labels, [d[pred_label] for d in datas])\n",
    "        model_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "        model_type, op1, op2 = model_name.split(\"-\")\n",
    "        k = (op1, op2)\n",
    "        if k not in results:\n",
    "            results[k] = []\n",
    "        results[k].append(balanced_acc)\n",
    "\n",
    "cleaned_results = []\n",
    "for (op1, op2), vs in results.items():\n",
    "    cleaned_results.append({\"op1\": op1, \"op2\": op2, \"score\": np.mean(vs)})\n",
    "    \n",
    "pd.DataFrame(cleaned_results).groupby([\"op1\", \"op2\"]).agg({\"score\": \"sum\"}).style.set_precision(3).set_caption(\"Balanced Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-31 14:15:34,909 [6185] WARNING  datasets.builder:355: [JupyterRequire] Using custom data configuration default\n",
      "2021-07-31 14:15:34,912 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "2021-07-31 14:15:39,162 [6185] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|██████████| 400/400 [00:00<00:00, 4027.15it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= cogensumm ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      " 38%|███▊      | 480/1250 [00:00<00:00, 4655.20it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= xsumfaith ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 4622.31it/s]\n",
      "100%|██████████| 634/634 [00:00<00:00, 4340.38it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= polytope ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "100%|██████████| 503/503 [00:00<00:00, 4521.10it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= factcc ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      " 52%|█████▏    | 440/850 [00:00<00:00, 4396.31it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= summeval ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 850/850 [00:00<00:00, 3651.48it/s]\n",
      " 30%|███       | 480/1575 [00:00<00:00, 4628.48it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= frank ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1575/1575 [00:00<00:00, 4369.67it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2\" ><caption>Balanced Accuracy</caption><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >score</th>    </tr>    <tr>        <th class=\"index_name level0\" >op1</th>        <th class=\"index_name level1\" >op2</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level0_row0\" class=\"row_heading level0 row0\" rowspan=3>max</th>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row0\" class=\"row_heading level1 row0\" >max</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row0_col0\" class=\"data row0 col0\" >0.691</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row1\" class=\"row_heading level1 row1\" >mean</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row1_col0\" class=\"data row1 col0\" >0.718</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row2\" class=\"row_heading level1 row2\" >min</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row2_col0\" class=\"data row2 col0\" >0.72</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level0_row3\" class=\"row_heading level0 row3\" rowspan=3>mean</th>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row3\" class=\"row_heading level1 row3\" >max</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row3_col0\" class=\"data row3 col0\" >0.62</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row4\" class=\"row_heading level1 row4\" >mean</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row4_col0\" class=\"data row4 col0\" >0.628</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row5\" class=\"row_heading level1 row5\" >min</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row5_col0\" class=\"data row5 col0\" >0.605</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level0_row6\" class=\"row_heading level0 row6\" rowspan=3>min</th>\n",
       "                        <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row6\" class=\"row_heading level1 row6\" >max</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row6_col0\" class=\"data row6 col0\" >0.574</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row7\" class=\"row_heading level1 row7\" >mean</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row7_col0\" class=\"data row7 col0\" >0.557</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2level1_row8\" class=\"row_heading level1 row8\" >min</th>\n",
       "                        <td id=\"T_6376140c_f22b_11eb_a7ae_f3abb70468b2row8_col0\" class=\"data row8 col0\" >0.531</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7faab5878250>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Max Doc Sents"
   ],
   "metadata": {
    "heading_collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "scorers = []\n",
    "for max_doc_sents in [1, 2, 4, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 100]:\n",
    "    scorers.append({\"name\": \"mds-%d\" % (max_doc_sents), \"model\": SummaCZS(granularity=\"sentence\", model_name=\"vitc\", max_doc_sents=max_doc_sents), \"sign\": 1})\n",
    "        \n",
    "scorer_doc = ScorerWrapper(scorers, max_batch_size=20, use_caching=True)\n",
    "print(\"%d scorers loaded\" % (len(scorers)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14 scorers loaded\n"
     ]
    }
   ],
   "metadata": {
    "hidden": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "benchmark = SummaCBenchmark(cut=\"val\")\n",
    "\n",
    "results = {}\n",
    "for dataset in benchmark.tasks:\n",
    "    print(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "    datas = dataset[\"task\"]\n",
    "    labels = [d[\"label\"] for d in datas]\n",
    "    utils_summac_benchmark.compute_doc_level(scorer_doc, datas)\n",
    "    \n",
    "    for pred_label in datas[0].keys():\n",
    "        if \"pred_\" not in pred_label or \"total\" in pred_label: continue\n",
    "        balanced_acc = sklearn.metrics.balanced_accuracy_score(labels, [d[pred_label] for d in datas])\n",
    "        model_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "        model_type, max_doc_sents = model_name.split(\"-\")\n",
    "        if max_doc_sents not in results:\n",
    "            results[max_doc_sents] = []\n",
    "        results[max_doc_sents].append(balanced_acc)\n",
    "\n",
    "cleaned_results = []\n",
    "for max_doc_sents, vs in results.items():\n",
    "    cleaned_results.append({\"max_doc_sents\": int(max_doc_sents), \"score\": np.mean(vs)})\n",
    "\n",
    "pd.DataFrame(cleaned_results).groupby([\"max_doc_sents\"]).agg({\"score\": \"sum\"}).style.set_precision(3).set_caption(\"Balanced Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-24 16:02:06,750 [11854] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset cnn_dailymail (/home/phillab/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "2021-07-24 16:02:07,532 [11854] WARNING  datasets.builder:355: [JupyterRequire] Using custom data configuration default\n",
      "2021-07-24 16:02:07,534 [11854] WARNING  datasets.builder:510: [JupyterRequire] Reusing dataset xsum (/home/phillab/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      " 45%|████▌     | 420/931 [00:00<00:00, 4078.50it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= factcc ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 931/931 [00:00<00:00, 4119.69it/s]\n",
      " 39%|███▊      | 260/671 [00:00<00:00, 2449.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= frank ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 671/671 [00:00<00:00, 2742.45it/s]\n",
      "100%|██████████| 634/634 [00:00<00:00, 4130.34it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= polytope ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      " 20%|██        | 260/1281 [00:00<00:00, 2495.64it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= cogensumm ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1281/1281 [00:00<00:00, 3604.15it/s]\n",
      " 49%|████▉     | 420/850 [00:00<00:00, 4095.00it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= summeval ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 850/850 [00:00<00:00, 3507.40it/s]\n",
      " 35%|███▌      | 440/1250 [00:00<00:00, 4315.12it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= xsumfaith ========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 4264.95it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9a\" ><caption>Balanced Accuracy</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >score</th>    </tr>    <tr>        <th class=\"index_name level0\" >max_doc_sents</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow0_col0\" class=\"data row0 col0\" >0.57</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow1_col0\" class=\"data row1 col0\" >0.623</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row2\" class=\"row_heading level0 row2\" >4</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow2_col0\" class=\"data row2 col0\" >0.665</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow3_col0\" class=\"data row3 col0\" >0.674</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row4\" class=\"row_heading level0 row4\" >10</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow4_col0\" class=\"data row4 col0\" >0.686</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row5\" class=\"row_heading level0 row5\" >15</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow5_col0\" class=\"data row5 col0\" >0.69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row6\" class=\"row_heading level0 row6\" >20</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow6_col0\" class=\"data row6 col0\" >0.689</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row7\" class=\"row_heading level0 row7\" >25</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow7_col0\" class=\"data row7 col0\" >0.69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row8\" class=\"row_heading level0 row8\" >30</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow8_col0\" class=\"data row8 col0\" >0.689</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row9\" class=\"row_heading level0 row9\" >35</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow9_col0\" class=\"data row9 col0\" >0.689</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row10\" class=\"row_heading level0 row10\" >40</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow10_col0\" class=\"data row10 col0\" >0.689</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row11\" class=\"row_heading level0 row11\" >45</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow11_col0\" class=\"data row11 col0\" >0.69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row12\" class=\"row_heading level0 row12\" >50</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow12_col0\" class=\"data row12 col0\" >0.69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9alevel0_row13\" class=\"row_heading level0 row13\" >100</th>\n",
       "                        <td id=\"T_2812fc84_ecba_11eb_88b2_757d12afdb9arow13_col0\" class=\"data row13 col0\" >0.69</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e5e1e96d0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "hidden": true
   }
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1625710190289,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}